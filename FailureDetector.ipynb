{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConocoPhillips Datathon Challenge\n",
    "\n",
    "ConocoPhillips give a challenge for [The TAMU Datathon](https://tamudatathon.com) to make a predictor for whether an oil rig would fail given a set of sensor values (107 columns).\n",
    "\n",
    "Here is our naive exploration of creating various classifiers to predict of a given state of sensor data would lead to a rig failure.\n",
    "\n",
    "## Authors\n",
    "\n",
    "* Aditya Pethe\n",
    "* Anikait Sharma\n",
    "* George Thayamkery\n",
    "* Jon Waterman\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# cleans training data\n",
    "def clean_data(training):\n",
    "    # change na's to 0\n",
    "    replace_na = training.replace('na',0)\n",
    "    return replace_na\n",
    "\n",
    "\n",
    "def read_file(filename):\n",
    "    raw_df = pd.read_csv(filename)\n",
    "    return raw_df\n",
    "\n",
    "def split_response(raw_df):\n",
    "    # get target vector\n",
    "    response = raw_df['target']\n",
    "\n",
    "    # get df of training data\n",
    "    training = raw_df.drop(columns=\"target\")\n",
    "    \n",
    "    return response, training\n",
    "\n",
    "# our simplest regression method (Logistical Regression)\n",
    "def logistic_regression(training,response):\n",
    "    X = training.drop(columns=\"id\")[:int(len(training) * 0.7)]\n",
    "    y = response[:int(len(training) * 0.7)]\n",
    "    \n",
    "    model = LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr').fit(X, y)\n",
    "    return model\n",
    "\n",
    "#Random Forest model\n",
    "def RandomForest(training,response):\n",
    "    X = training.drop(columns=\"id\")[:int(len(training) * 0.7)] # train on first 70% of data\n",
    "    y = response[:int(len(training) * 0.7)]\n",
    "    RF = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=0).fit(X, y)\n",
    "\n",
    "    return RF\n",
    "\n",
    "#support vector machines\n",
    "def vector_machine(training,response):\n",
    "    X = training.drop(columns=\"id\")[:int(len(training) * 0.7)] # train on 70% of data\n",
    "    Y = response[:int(len(training) * 0.7)]\n",
    "\n",
    "    SVM = svm.LinearSVC()\n",
    "    SVM.fit(X,Y)\n",
    "\n",
    "    return round(SVM.score(X,Y),4)\n",
    "    #SVM.predict(X.iloc[2:,:])\n",
    "\n",
    "def produce_prediction_vector(model, test_data):\n",
    "    result =model.predict(test_data)\n",
    "    # print(\"length:\", len(result))\n",
    "    print(\"length:\", len(result))\n",
    "    # test_data = pd.DataFrame(result.T)\n",
    "    final_str = \"id,target\\n\"\n",
    "    for i, r in enumerate(result):\n",
    "        final_str += str(i+1) + \",\" + str(r) + \"\\n\"\n",
    "    \n",
    "    f = open(\"result4.csv\", \"w+\")\n",
    "    f.write(final_str)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data and make models\n",
    "We replaced all the `na` sensor readings in the data to zeroes and created Logistic Regression, Random Forest, and Vector Machine models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in training set\n",
    "filename = \"equip_failures_training_set.csv\"\n",
    "df = read_file(filename) \n",
    "response, training = split_response(df) # for now training contains ID column, but is dropped when training \n",
    "\n",
    "# clean training data\n",
    "training = clean_data(training)\n",
    "\n",
    "# generate logistic regression model\n",
    "model = logistic_regression(training,response)\n",
    "\n",
    "# generate random forest model\n",
    "rf_model = RandomForest(training,response)\n",
    "\n",
    "# generate SVM model\n",
    "svm_model = vector_machine(training,response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "We got the best results when training our models on 70% of the given training set and testing it on the remaining 30% of the training set. This is apparently a strategy real data scientists use to prevent overfitting.\n",
    "\n",
    "We did not spend to much time tweaking things but the Random Forest model performed the best (especially after only training it on 70% of the training set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing LR against training: 0.9896666666666667\n",
      "testing RF against training: 0.9933888888888889\n",
      "testing SVM against training: 0.9933888888888889\n"
     ]
    }
   ],
   "source": [
    "# test LR against training data (the remaining 30% after training after first 70%)\n",
    "print(\"testing LR against training:\",model.score(training.drop(columns=\"id\")[int(len(training) * 0.7):], response[int(len(training) * 0.7):]))\n",
    "\n",
    "# test RF against training data (the remaining 30% after training after first 70%) (Best model we came up with!!!)\n",
    "print(\"testing RF against training:\",rf_model.score(training.drop(columns=\"id\")[int(len(training) * 0.7):], response[int(len(training) * 0.7):]))\n",
    "\n",
    "# test SVM against training data (the remaining 30% after training after first 70%)\n",
    "print(\"testing SVM against training:\",rf_model.score(training.drop(columns=\"id\")[int(len(training) * 0.7):], response[int(len(training) * 0.7):]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the best model to predict the test set\n",
    "In the end, we placed 38/70 (accuracy: 0.992)  on the [kaggle for this challenge](https://www.kaggle.com/c/equipfails/) (which is higher then we certainly expected) using the random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the RF model is the best, so lets put it up against the test dataset and upload that vector to kaggle\n",
    "\n",
    "# test RF model on test file and put resulting vector into csv\n",
    "filename = \"equip_failures_test_set.csv\"\n",
    "\n",
    "test_df = read_file(filename)\n",
    "test_df = clean_data(test_df)\n",
    "\n",
    "# run model through test dataframe and produce csv\n",
    "produce_prediction_vector(rf_model, test_df.drop(columns=\"id\"))"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
